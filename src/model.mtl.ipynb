{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTL in Detection of Emotion, Toxicity Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build.pytorch import preprocessing\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch_directml as td\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_device(device=''):\n",
    "    if device.lower() == 'cuda':\n",
    "        if not torch.cuda.is_available():\n",
    "            print (\"torch.cuda not available\")\n",
    "            return torch.device('cpu')    \n",
    "        else:\n",
    "            return torch.device('cuda:0')\n",
    "    if device.lower() == 'dml':\n",
    "        return td.device(td.default_device())\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = select_device('dml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 688 entries, 0 to 687\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   username  688 non-null    object \n",
      " 1   chat      688 non-null    object \n",
      " 2   is_self   98 non-null     float64\n",
      " 3   emotion   688 non-null    object \n",
      " 4   toxicity  686 non-null    object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 27.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/unrevised_Dataset_ChattyTicket.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['is_self'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 686 entries, 0 to 687\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   username  686 non-null    object\n",
      " 1   chat      686 non-null    object\n",
      " 2   emotion   686 non-null    object\n",
      " 3   toxicity  686 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 26.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Check all the classes\n",
    "\n",
    "`toxicity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxicity\n",
       "positive           200\n",
       "neutral            159\n",
       "cyberbullying      133\n",
       "sarcasm             89\n",
       "blaming others      22\n",
       "EBR complaints      20\n",
       "SPG complaints      18\n",
       "sexism              16\n",
       "male preserve        7\n",
       "RNG complaints       6\n",
       "Game complaints      5\n",
       "ableism              5\n",
       "racism               2\n",
       "ageism               1\n",
       "Gamesplaining        1\n",
       "Map complaints       1\n",
       "MM complaints        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxicity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`emotion / sentiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "negative    312\n",
       "positive    235\n",
       "neutral     139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../dataset/preprocessed_df.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Declaring Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_SEQ_LEN = 128\n",
    "LSTM_UNITS = 64\n",
    "BATCHES = 16\n",
    "# VOCAB_SIZE = 10000\n",
    "# EMBEDDING_DIM = 128\n",
    "# Task-specific constants\n",
    "NUM_EMOTION_CLASSES = 7\n",
    "# NUM_SENTIMENT_CLASSES = 3\n",
    "NUM_TOXICITY_CLASSES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "\n",
    "DROP_OUT = 0.6 # Drop out regularization based in percentage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Mini Projects\\Thesis\\model-multitask-learning\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load tokenizer\n",
    "TOKENIZER = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = preprocessing.ValorantChatDataset(train_data['chat'].values, train_data['emotion'].values, train_data['toxicity'].values, TOKENIZER)\n",
    "test_dataset = preprocessing.ValorantChatDataset(test_data['chat'].values, test_data['emotion'].values, test_data['toxicity'].values, TOKENIZER)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCHES, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCHES, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset._category_to_one_hot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the input Layer and Bert Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/35 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([16, 17])) that is different to the input size (torch.Size([16, 1536])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Mini Projects\\Thesis\\model-multitask-learning\\src\\model.mtl.ipynb Cell 23\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Mini%20Projects/Thesis/model-multitask-learning/src/model.mtl.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Mini%20Projects/Thesis/model-multitask-learning/src/model.mtl.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Mini%20Projects/Thesis/model-multitask-learning/src/model.mtl.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     train_fn(model, criterion, optimizer, train_dataloader,device, epoch, epochs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Mini%20Projects/Thesis/model-multitask-learning/src/model.mtl.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     evaluate_fn(model, test_dataloader, device)\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\model-multitask-learning\\src\\utils\\utils.py:58\u001b[0m, in \u001b[0;36mtrain_fn\u001b[1;34m(model, criterion, optimizer, data_loader, device, epoch, total_epoch)\u001b[0m\n\u001b[0;32m     55\u001b[0m toxicity_logits, emotion_logits, toxicity_probs, emotion_probs \u001b[39m=\u001b[39m model(input_ids, attention_mask)\n\u001b[0;32m     56\u001b[0m \u001b[39m# print(raw_emotion_labels)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# Calculate Loss\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m toxicity_loss \u001b[39m=\u001b[39m criterion(toxicity_logits, toxicity_labels)\n\u001b[0;32m     59\u001b[0m emotion_loss \u001b[39m=\u001b[39m criterion(motion_logits, emotion_labels)\n\u001b[0;32m     60\u001b[0m loss \u001b[39m=\u001b[39m toxicity_loss \u001b[39m+\u001b[39m emotion_loss\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\model-multitask-learning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\model-multitask-learning\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32me:\\Mini Projects\\Thesis\\model-multitask-learning\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:3089\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3087\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3088\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[1;32m-> 3089\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   3090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3091\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m   3092\u001b[0m     )\n\u001b[0;32m   3094\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3095\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([16, 17])) that is different to the input size (torch.Size([16, 1536])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "from utils.utils import train_fn, evaluate_fn\n",
    "from utils.config import criterion, optimizer, model\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_fn(model, criterion, optimizer, train_dataloader,device, epoch, epochs)\n",
    "    evaluate_fn(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
